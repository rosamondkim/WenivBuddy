import { NextResponse } from 'next/server'
import crypto from 'crypto'
import { filterOCRText } from '@/lib/ocr-text-filter'

/**
 * OCR ê²°ê³¼ ìºì‹œ (ì´ë¯¸ì§€ í•´ì‹œ ê¸°ë°˜)
 * ê°™ì€ ì´ë¯¸ì§€ë¡œ ì¬ê²€ìƒ‰ ì‹œ ì¤‘ë³µ OCR í˜¸ì¶œ ë°©ì§€
 */
const ocrCache = new Map()
const CACHE_TTL = 15 * 60 * 1000 // 15ë¶„
const MAX_CACHE_SIZE = 100

/**
 * ì´ë¯¸ì§€ í•´ì‹œ ê³„ì‚° (MD5)
 */
function calculateImageHash(buffer) {
  return crypto.createHash('md5').update(buffer).digest('hex')
}

/**
 * ìºì‹œ ì •ë¦¬ (ì˜¤ë˜ëœ í•­ëª© ë° í¬ê¸° ì œí•œ)
 */
function cleanCache() {
  const now = Date.now()

  // ë§Œë£Œëœ í•­ëª© ì œê±°
  for (const [hash, entry] of ocrCache.entries()) {
    if (now - entry.timestamp > CACHE_TTL) {
      ocrCache.delete(hash)
    }
  }

  // í¬ê¸° ì œí•œ ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ í•­ëª©ë¶€í„° ì œê±°
  if (ocrCache.size > MAX_CACHE_SIZE) {
    const entries = Array.from(ocrCache.entries())
      .sort((a, b) => a[1].timestamp - b[1].timestamp)

    const toDelete = entries.slice(0, ocrCache.size - MAX_CACHE_SIZE)
    toDelete.forEach(([hash]) => ocrCache.delete(hash))
  }
}

/**
 * Hallucination ê°ì§€ í•¨ìˆ˜
 * OCR ê²°ê³¼ê°€ í™˜ê°ì¸ì§€ í™•ì¸
 *
 * ì£¼ì˜: íŠ¹ì • í‚¤ì›Œë“œ ìì²´ë¥¼ ì°¨ë‹¨í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼,
 * ë§¤ìš° ì˜ì‹¬ìŠ¤ëŸ¬ìš´ "íŒ¨í„´ ì¡°í•©"ë§Œ ê°ì§€í•©ë‹ˆë‹¤.
 */
function isHallucination(text) {
  if (!text) return false

  // [NO_TEXT] ì‘ë‹µ
  const looksNoText = /\[NO_TEXT\]/i.test(text)
  if (looksNoText) return true

  // ë¹„ì •ìƒì ìœ¼ë¡œ ê¸´ í…ìŠ¤íŠ¸ (ì¼ë°˜ì ì¸ ìŠ¤í¬ë¦°ìƒ·ë³´ë‹¤ í›¨ì”¬ ê¹€)
  const tooLong = text.length > 1500
  if (tooLong) {
    console.warn(`âš ï¸ [OCR] Text too long (${text.length} chars) - possible hallucination`)
    return true
  }

  // ë§¤ìš° êµ¬ì²´ì ì¸ í™˜ê° íŒ¨í„´ë§Œ ì°¨ë‹¨
  // "gemini" ëª…ë ¹ì–´ì™€ PowerShell ì—ëŸ¬ê°€ ë™ì‹œì— ë‚˜íƒ€ë‚˜ëŠ” íŒ¨í„´
  // (ì‹¤ì œ ì´ë¯¸ì§€ì— geminiê°€ ì—†ëŠ”ë° ì´ëŸ° í…ìŠ¤íŠ¸ê°€ ë‚˜ì˜¤ë©´ í™˜ê°)
  const suspiciousGeminiPattern = /gemini.*powershell.*executionpolic/is

  if (suspiciousGeminiPattern.test(text)) {
    console.warn('âš ï¸ [OCR] Suspicious gemini+powershell pattern detected')
    return true
  }

  // ê¸°íƒ€ í™˜ê° íŒ¨í„´ì€ ì¼ë‹¨ í—ˆìš© (OCR í”„ë¡¬í”„íŠ¸ ê°œì„ ìœ¼ë¡œ í•´ê²°)
  return false
}

/**
 * OpenAI Vision APIë¥¼ ì‚¬ìš©í•œ OCR (ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
 * POST /api/ocr
 */
export async function POST(request) {
  try {
    // FormDataì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì¶”ì¶œ
    const formData = await request.formData()
    const imageFile = formData.get('image')

    if (!imageFile) {
      return NextResponse.json(
        { error: 'Image file is required' },
        { status: 400 }
      )
    }

    // API í‚¤ í™•ì¸
    const apiKey = process.env.OPENAI_API_KEY
    if (!apiKey) {
      console.warn('âš ï¸ OPENAI_API_KEY not found in environment variables')
      return NextResponse.json(
        { error: 'OpenAI API key not configured' },
        { status: 500 }
      )
    }

    console.log(`ğŸ–¼ï¸ [OCR] Processing image: ${imageFile.name} (${imageFile.size} bytes)`)

    // ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
    const bytes = await imageFile.arrayBuffer()
    const buffer = Buffer.from(bytes)

    // ì´ë¯¸ì§€ í•´ì‹œ ê³„ì‚°
    const imageHash = calculateImageHash(buffer)
    console.log(`ğŸ”‘ [OCR Cache] Image hash: ${imageHash}`)

    // ìºì‹œ í™•ì¸
    cleanCache() // ìºì‹œ ì •ë¦¬
    const cachedResult = ocrCache.get(imageHash)

    if (cachedResult) {
      console.log(`âœ… [OCR Cache] Cache hit! Returning cached result`)
      return NextResponse.json({
        ...cachedResult.data,
        cached: true,
        cacheAge: Date.now() - cachedResult.timestamp
      })
    }

    console.log(`âŒ [OCR Cache] Cache miss - calling OpenAI API`)

    const base64Image = buffer.toString('base64')

    // ì´ë¯¸ì§€ íƒ€ì… í™•ì¸
    const imageType = imageFile.type || 'image/png'

    // OpenAI Vision API í˜¸ì¶œ
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: `ë‹¹ì‹ ì€ ì—ëŸ¬/ì½”ë“œ ìŠ¤í¬ë¦°ìƒ·ì—ì„œ "ë³´ì´ëŠ” í…ìŠ¤íŠ¸ë§Œ" ì¶”ì¶œí•˜ëŠ” OCR ë„ìš°ë¯¸ì…ë‹ˆë‹¤.
- ì¶”ì¸¡Â·ì¶”ë¡ Â·ìƒì„± ê¸ˆì§€. ì´ë¯¸ì§€ì— ì—†ëŠ” ë‹¨ì–´/ë¬¸ì¥ì€ ì ˆëŒ€ ë§Œë“¤ì§€ ë§ˆì„¸ìš”.
- í…ìŠ¤íŠ¸ê°€ ì „í˜€ ì—†ìœ¼ë©´ [NO_TEXT]ë§Œ ë°˜í™˜í•˜ì„¸ìš”.
- UI ë²„íŠ¼/ë©”ë‰´/íˆ´íŒ ë“± ë¶ˆí•„ìš”í•œ UI í…ìŠ¤íŠ¸ëŠ” ì œì™¸í•˜ì„¸ìš”.
- ì½”ë“œ/ì—ëŸ¬/íŒŒì¼ ê²½ë¡œê°€ ë³´ì´ë©´ ì¤„ë°”ê¿ˆê³¼ ë“¤ì—¬ì“°ê¸°ë¥¼ ìœ ì§€í•´ ê·¸ëŒ€ë¡œ ì ìœ¼ì„¸ìš”.
- í™•ì‹ ì´ ì—†ìœ¼ë©´ í•´ë‹¹ ì¤„ì„ ìƒëµí•˜ê±°ë‚˜ [UNCERTAIN]ìœ¼ë¡œ í‘œì‹œí•˜ì§€ ë§ê³ , ì•„ì˜ˆ ì ì§€ ë§ˆì„¸ìš”.`
          },
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: 'ì•„ë˜ ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ì‹¤ì œ í…ìŠ¤íŠ¸(ì—ëŸ¬, ì½”ë“œ, ê²½ë¡œ ë“±)ë¥¼ ê·¸ëŒ€ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”. ì¶”ê°€ ì„¤ëª… ì—†ì´ í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ì„¸ìš”. í…ìŠ¤íŠ¸ê°€ ì—†ìœ¼ë©´ [NO_TEXT].'
              },
              {
                type: 'image_url',
                image_url: {
                  url: `data:${imageType};base64,${base64Image}`,
                  detail: 'high'
                }
              }
            ]
          }
        ],
        max_tokens: 1500,
        temperature: 0
      })
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('âŒ [OCR] OpenAI API error:', response.status, errorText)

      // íŠ¹ì • ì—ëŸ¬ ì²˜ë¦¬
      if (response.status === 401) {
        return NextResponse.json(
          { error: 'OpenAI API key is invalid' },
          { status: 500 }
        )
      }
      if (response.status === 429) {
        return NextResponse.json(
          { error: 'Rate limit exceeded. Please try again later.' },
          { status: 429 }
        )
      }

      return NextResponse.json(
        { error: `OpenAI API error: ${response.status}` },
        { status: response.status }
      )
    }

    const data = await response.json()

    // OpenAI API ì‘ë‹µì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸
    const extractedText = data.choices[0].message.content.trim()

    console.log(`ğŸ“Š [OCR] Extracted text length: ${extractedText.length} chars`)
    console.log(`ğŸ’° [OCR] Token usage: ${data.usage.total_tokens} tokens`)

    // Hallucination ê²€ì¦
    if (isHallucination(extractedText)) {
      console.warn(`âŒ [OCR] Hallucination detected - returning empty text`)

      // í™˜ê°ìœ¼ë¡œ íŒë‹¨ë˜ë©´ ë¹ˆ ê²°ê³¼ ë°˜í™˜ (ìºì‹œì—ëŠ” ì €ì¥í•˜ì§€ ì•ŠìŒ)
      return NextResponse.json({
        text: '',
        model: 'gpt-4o-mini',
        usage: data.usage,
        note: 'hallucination suspected - returned empty text',
        imageSize: imageFile.size,
        imageType: imageFile.type
      })
    }

    console.log(`âœ… [OCR] Validation passed - returning extracted text`)

    // í„°ë¯¸ë„ ì—ëŸ¬ í…ìŠ¤íŠ¸ ì •ì œ (í”„ë¡¬í”„íŠ¸, ê²½ë¡œ ë“± ì œê±°)
    const filteredText = filterOCRText(extractedText)
    const reductionPercent = Math.round((1 - filteredText.length / extractedText.length) * 100)

    if (filteredText !== extractedText) {
      console.log(`ğŸ”§ [OCR] Text filtered: ${extractedText.length} â†’ ${filteredText.length} chars (${reductionPercent}% reduction)`)
    }

    // ì„±ê³µí•œ ê²°ê³¼ë¥¼ ìºì‹œì— ì €ì¥ (ì •ì œëœ í…ìŠ¤íŠ¸ ì‚¬ìš©)
    const result = {
      text: filteredText,
      originalText: extractedText,  // ë””ë²„ê¹…ìš© ì›ë³¸ ë³´ê´€
      model: 'gpt-4o-mini',
      usage: data.usage,
      imageSize: imageFile.size,
      imageType: imageFile.type,
      filtered: filteredText !== extractedText  // í•„í„°ë§ ì—¬ë¶€
    }

    ocrCache.set(imageHash, {
      data: result,
      timestamp: Date.now()
    })

    console.log(`ğŸ’¾ [OCR Cache] Cached result for hash: ${imageHash} (cache size: ${ocrCache.size})`)

    return NextResponse.json(result)

  } catch (error) {
    console.error('âŒ [OCR] Error:', error)
    return NextResponse.json(
      { error: error.message || 'Internal server error' },
      { status: 500 }
    )
  }
}
