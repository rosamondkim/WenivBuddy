import { NextResponse } from 'next/server'

/**
 * OpenAI Vision APIë¥¼ ì‚¬ìš©í•œ OCR (ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ)
 * POST /api/ocr
 */
export async function POST(request) {
  try {
    // FormDataì—ì„œ ì´ë¯¸ì§€ íŒŒì¼ ì¶”ì¶œ
    const formData = await request.formData()
    const imageFile = formData.get('image')

    if (!imageFile) {
      return NextResponse.json(
        { error: 'Image file is required' },
        { status: 400 }
      )
    }

    // API í‚¤ í™•ì¸
    const apiKey = process.env.OPENAI_API_KEY
    if (!apiKey) {
      console.warn('âš ï¸ OPENAI_API_KEY not found in environment variables')
      return NextResponse.json(
        { error: 'OpenAI API key not configured' },
        { status: 500 }
      )
    }

    console.log(`ğŸ–¼ï¸ [OCR] Processing image: ${imageFile.name} (${imageFile.size} bytes)`)

    // ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
    const bytes = await imageFile.arrayBuffer()
    const buffer = Buffer.from(bytes)
    const base64Image = buffer.toString('base64')

    // ì´ë¯¸ì§€ íƒ€ì… í™•ì¸
    const imageType = imageFile.type || 'image/png'

    // OpenAI Vision API í˜¸ì¶œ
    const response = await fetch('https://api.openai.com/v1/chat/completions', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${apiKey}`
      },
      body: JSON.stringify({
        model: 'gpt-4o-mini',
        messages: [
          {
            role: 'system',
            content: `ë‹¹ì‹ ì€ ì—ëŸ¬ í™”ë©´ ë° ì½”ë“œ ìŠ¤í¬ë¦°ìƒ·ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì´ë¯¸ì§€ì—ì„œ ë³´ì´ëŠ” ëª¨ë“  í…ìŠ¤íŠ¸, ì—ëŸ¬ ë©”ì‹œì§€, ì½”ë“œ, ê²½ë¡œ ë“±ì„ ì •í™•í•˜ê²Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

ì¶”ì¶œ ê·œì¹™:
1. ì—ëŸ¬ ë©”ì‹œì§€ê°€ ìˆë‹¤ë©´ ê°€ì¥ ë¨¼ì € ì¶”ì¶œ
2. ì½”ë“œëŠ” ë“¤ì—¬ì“°ê¸°ë¥¼ ìœ ì§€í•˜ì—¬ ì¶”ì¶œ
3. íŒŒì¼ ê²½ë¡œ, URLì´ ìˆë‹¤ë©´ ì •í™•í•˜ê²Œ ì¶”ì¶œ
4. ì¤„ ë²ˆí˜¸ê°€ ìˆë‹¤ë©´ í¬í•¨
5. ë¶ˆí•„ìš”í•œ UI ìš”ì†Œ (ë²„íŠ¼ í…ìŠ¤íŠ¸, ë©”ë‰´ ë“±)ëŠ” ì œì™¸

í…ìŠ¤íŠ¸ë§Œ ë°˜í™˜í•˜ê³ , ì¶”ê°€ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.`
          },
          {
            role: 'user',
            content: [
              {
                type: 'text',
                text: 'ì´ ì´ë¯¸ì§€ì—ì„œ ì—ëŸ¬ ë©”ì‹œì§€ì™€ ê´€ë ¨ ì½”ë“œ/ì •ë³´ë¥¼ ì¶”ì¶œí•´ì£¼ì„¸ìš”.'
              },
              {
                type: 'image_url',
                image_url: {
                  url: `data:${imageType};base64,${base64Image}`,
                  detail: 'high'
                }
              }
            ]
          }
        ],
        max_tokens: 2000,
        temperature: 0.1
      })
    })

    if (!response.ok) {
      const errorText = await response.text()
      console.error('âŒ [OCR] OpenAI API error:', response.status, errorText)

      // íŠ¹ì • ì—ëŸ¬ ì²˜ë¦¬
      if (response.status === 401) {
        return NextResponse.json(
          { error: 'OpenAI API key is invalid' },
          { status: 500 }
        )
      }
      if (response.status === 429) {
        return NextResponse.json(
          { error: 'Rate limit exceeded. Please try again later.' },
          { status: 429 }
        )
      }

      return NextResponse.json(
        { error: `OpenAI API error: ${response.status}` },
        { status: response.status }
      )
    }

    const data = await response.json()

    // OpenAI API ì‘ë‹µì—ì„œ ì¶”ì¶œëœ í…ìŠ¤íŠ¸
    const extractedText = data.choices[0].message.content

    console.log(`âœ… [OCR] Successfully extracted text (${extractedText.length} chars, ${data.usage.total_tokens} tokens)`)
    console.log(`ğŸ“ [OCR] Preview: ${extractedText.substring(0, 200)}...`)

    return NextResponse.json({
      text: extractedText,
      model: 'gpt-4o-mini',
      usage: data.usage,
      imageSize: imageFile.size,
      imageType: imageFile.type
    })

  } catch (error) {
    console.error('âŒ [OCR] Error:', error)
    return NextResponse.json(
      { error: error.message || 'Internal server error' },
      { status: 500 }
    )
  }
}
