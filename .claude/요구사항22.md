# 질문

1. OCR이 호출되는 경우

   - 검색 시 (가장 빈번)
     이미지를 첨부하고 "검색하기" 클릭 시마다 OCR 호출
     같은 이미지로 재검색해도 매번 호출 (중복)
   - Q&A 추가 폼
     질문/답변 필드에 이미지 붙여넣을 때마다 OCR 호출
     이미지 업로드와 OCR을 동시 처리
   - OCR 모드에서 LLM 강제 사용
   - OCR 텍스트 감지 시 무조건 LLM 호출
   - OCR 1회 + LLM 1회 = 2회 API 호출
   - 문제점
     중복 호출: 같은 이미지로 여러 번 검색 시 매번 OCR 호출
     캐싱 없음: 이미지 해시 기반 캐싱 없음
     LLM 강제: OCR 모드에서 로컬 추출을 건너뛰고 바로 LLM 호출

   OCR 과다 호출인 이 구조를 개선할 필요가 있어보여

# 답변

## 개선 완료 내용

### 문제점 분석

**기존 구조의 문제**:
1. ❌ 같은 이미지로 재검색 시 매번 OCR API 호출 (중복 호출)
2. ❌ 이미지 해시 기반 캐싱이 없어서 비용 낭비
3. ❌ OCR 모드에서 무조건 LLM 강제 호출 (로컬 추출 건너뜀)
4. ❌ OCR 1회 + LLM 1회 = 총 2회 API 호출로 비용 증가

### 개선 1: OCR 결과 캐싱 시스템 구현

**수정 파일**: `app/api/ocr/route.js`

#### 캐싱 전략

```javascript
// 이미지 해시 기반 캐싱
const ocrCache = new Map()
const CACHE_TTL = 15 * 60 * 1000 // 15분
const MAX_CACHE_SIZE = 100
```

#### 구현 내용

1. **이미지 해시 계산** (MD5)
   - 이미지 내용을 MD5 해시로 변환
   - 같은 이미지는 같은 해시값 생성

2. **캐시 확인 및 반환**
   ```javascript
   // 캐시 확인
   const cachedResult = ocrCache.get(imageHash)
   if (cachedResult) {
     console.log('✅ [OCR Cache] Cache hit! Returning cached result')
     return cachedResult
   }
   ```

3. **캐시 저장**
   - OCR 성공 시 결과를 캐시에 저장
   - 환각(hallucination) 감지된 결과는 캐시 제외

4. **자동 캐시 정리**
   - 15분 경과한 항목 자동 삭제
   - 최대 100개 항목 유지 (메모리 관리)

#### 효과

✅ **API 호출 감소**: 같은 이미지 재검색 시 캐시에서 즉시 반환
- 첫 검색: OCR API 호출 (OpenAI Vision)
- 재검색 (15분 내): 캐시에서 반환 (API 호출 없음)

✅ **비용 절감**: 중복 OCR 호출 제거
- 추정 절감: 재검색이 50%라고 가정 시, OCR 비용 50% 절감

✅ **응답 속도 향상**: 캐시 히트 시 즉시 반환 (네트워크 지연 없음)

---

### 개선 2: OCR 모드 LLM 강제 호출 로직 개선

**수정 파일**: `lib/hybrid-keyword-extractor.js`

#### 기존 로직 (문제)

```javascript
// ❌ OCR 모드면 무조건 LLM 강제 사용
const shouldForceLLM = forceLLM || isOCR

if (isOCR) {
  console.log('🖼️ OCR text detected - forcing LLM extraction')
}
```

**문제점**:
- OCR 텍스트라도 로컬 추출이 잘 될 수 있는데 무조건 LLM 호출
- 비용 낭비: OCR + LLM = 2회 API 호출
- 예: "node : 'node' 용어가 cmdlet, 함수, 스크립트 파일 또는 실행할 수 있는 프로그램 이름으로 인식되지 않습니다"
  → 로컬 추출로도 "node", "PowerShell", "cmdlet" 등 충분히 추출 가능

#### 개선 로직

```javascript
// ✅ OCR 모드에서도 신뢰도가 높으면 로컬 사용
const effectiveThreshold = isOCR ? 0.8 : 0.7
const shouldForceLLM = forceLLM  // isOCR 제거

if (isOCR) {
  console.log('🖼️ OCR mode - using higher threshold (80%)')
}

// 신뢰도 기반 처리
if (!shouldForceLLM && confidence >= effectiveThreshold) {
  // 로컬 결과 사용 (OCR 모드에서도!)
  return { keywords, source: 'local', cost: 0 }
} else {
  // 신뢰도 낮을 때만 LLM 호출
  return { keywords, source: 'llm', cost: 0.0001 }
}
```

#### 처리 흐름

**OCR 모드 (isOCR = true)**:
1. 로컬 키워드 추출 시도
2. 신뢰도 계산
3. **신뢰도 ≥ 80%**: ✅ 로컬 결과 사용 (비용 $0)
4. **신뢰도 < 80%**: 🤖 LLM 호출 (비용 ~$0.0001)

**일반 모드 (isOCR = false)**:
1. 로컬 키워드 추출 시도
2. 신뢰도 계산
3. **신뢰도 ≥ 70%**: ✅ 로컬 결과 사용 (비용 $0)
4. **신뢰도 < 70%**: 🤖 LLM 호출 (비용 ~$0.0001)

#### 신뢰도 판단 기준

OCR 모드에서 **높은 신뢰도 (80% 이상)** 조건:
- 기술 용어 포함 (React, Git, node, PowerShell 등)
- 키워드 3개 이상 추출
- 영문 키워드 비율 높음

예시:
```
입력: "node : 'node' 용어가 cmdlet, 함수, 스크립트 파일 또는..."
↓
로컬 추출: ["node", "PowerShell", "cmdlet", "스크립트", "프로그램"]
신뢰도: 85% (기술 용어 포함 + 5개 키워드)
↓
결과: ✅ 로컬 사용 (LLM 호출 X)
```

#### 효과

✅ **LLM 호출 감소**:
- 기존: OCR 모드 100% LLM 호출
- 개선: OCR 모드에서도 신뢰도 높으면 로컬 사용
- 추정: 40~60%의 OCR 케이스에서 로컬만 사용 가능

✅ **비용 절감**:
- 기존: OCR ($0.001) + LLM ($0.0001) = $0.0011 per request
- 개선 (신뢰도 높음): OCR ($0.001) = $0.001 per request
- 절감: ~10% 비용 감소

✅ **품질 유지**:
- OCR 임계값을 80%로 높여서 엄격한 기준 적용
- 신뢰도 낮을 때는 여전히 LLM 사용으로 품질 보장

---

## 전체 개선 효과

### API 호출 흐름 비교

**개선 전**:
```
사용자 검색 (이미지 첨부)
  ↓
OCR API 호출 ($0.001)
  ↓
LLM API 호출 (OCR 모드 강제) ($0.0001)
  ↓
총 비용: $0.0011

재검색 (같은 이미지)
  ↓
OCR API 호출 (중복!) ($0.001)
  ↓
LLM API 호출 ($0.0001)
  ↓
총 비용: $0.0011 (중복!)
```

**개선 후**:
```
사용자 검색 (이미지 첨부)
  ↓
이미지 해시 계산
  ↓
캐시 확인 → 없음
  ↓
OCR API 호출 ($0.001)
  ↓
캐시 저장
  ↓
로컬 키워드 추출
  ↓
신뢰도 85% (높음)
  ↓
로컬 결과 사용 (LLM 호출 X)
  ↓
총 비용: $0.001

재검색 (같은 이미지, 15분 내)
  ↓
이미지 해시 계산
  ↓
캐시 확인 → 있음!
  ↓
캐시에서 즉시 반환 (API 호출 X)
  ↓
로컬 키워드 추출
  ↓
신뢰도 85%
  ↓
로컬 결과 사용
  ↓
총 비용: $0 (완전 무료!)
```

### 비용 절감 효과 (추정)

**가정**:
- 일일 OCR 검색: 100회
- 재검색 비율: 50% (같은 이미지로 다시 검색)
- 로컬 신뢰도 높음: 50% (OCR 모드에서도 로컬 사용 가능)

**개선 전**:
- 총 OCR 호출: 100회 × $0.001 = $0.1
- 총 LLM 호출: 100회 × $0.0001 = $0.01
- **일일 비용: $0.11**
- **월간 비용: $3.3**

**개선 후**:
- 총 OCR 호출: 50회 (캐시로 50% 절감) × $0.001 = $0.05
- 총 LLM 호출: 25회 (로컬 사용으로 50% 절감) × $0.0001 = $0.0025
- **일일 비용: $0.0525**
- **월간 비용: $1.575**

**절감**: 약 **52% 비용 절감** ($1.725/월)

### 사용자 경험 개선

✅ **응답 속도 향상**:
- 재검색 시 캐시 히트 → 즉시 반환 (수십 ms)
- OCR API 대기 시간 제거 (보통 1~3초)

✅ **정확도 유지**:
- OCR 임계값 80%로 엄격한 기준 적용
- 신뢰도 낮을 때는 여전히 LLM 사용

✅ **서버 부하 감소**:
- API 호출 감소로 서버 부담 경감
- 캐시 메모리 사용은 최소 (최대 100개 항목)

---

## 추가 최적화 가능성

### 향후 개선 방안

1. **Redis 캐싱**: 서버 재시작 시에도 캐시 유지
2. **캐시 프리로딩**: 자주 검색되는 이미지 미리 캐싱
3. **신뢰도 학습**: 로컬/LLM 선택 정확도를 학습으로 개선
4. **OCR 배치 처리**: 여러 이미지를 한 번에 처리

### 모니터링 지표

개선 효과를 측정하기 위한 주요 지표:
- 캐시 히트율 (Cache Hit Rate)
- OCR API 호출 횟수
- LLM API 호출 횟수
- 평균 응답 시간
- 월간 API 비용
